{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Course:** Randomized Algorithms by Dr. Zarei\n",
        "\n",
        "**Homework:** HW3\n",
        "\n",
        "**Name:** Mohammad Mohammadi\n",
        "\n",
        "**Student ID:** 402208592"
      ],
      "metadata": {
        "id": "9JbKLJNkfqlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6.3.15. [DARA_Hor]\n",
        "\n",
        "Prove the properties (iii), (iv), and (v) of Jacobi symbols presented below:\n",
        "\n",
        "(III) $$\\mathrm{Jac}\\left[ \\frac{a}{n} \\right] = (-1)^{\\frac{a-1}{2} \\cdot \\frac{n-1}{2}} \\cdot \\mathrm{Jac}\\left[ \\frac{n}{a} \\right] \\text{ for all odd } a,$$\n",
        "\n",
        "(IV) $$ \\mathrm{Jac}\\left[ \\frac{1}{n} \\right] = 1, \\text{ and } \\mathrm{Jac}\\left[ \\frac{n-1}{n} \\right] = (-1)^{\\left(\\frac{n-1}{2}\\right)},$$\n",
        "\n",
        "(V) $$\\mathrm{Jac}\\left[ \\frac{2}{n} \\right] = -1 \\text{ for all } n \\text{ with } n \\mod 8 \\in \\{3, 5\\}, \\text{ and } \\mathrm{Jac}\\left[ \\frac{2}{n} \\right] = 1 \\text{ for all } n \\text{ with } n \\mod 8 \\in \\{1, 7\\}.$$"
      ],
      "metadata": {
        "id": "TNS-hA4yyNoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer"
      ],
      "metadata": {
        "id": "qCTFxLj-P41G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (III)\n",
        "\n",
        "This is called the law of Quadratic Reciprocity and it holds true for Legendre symbols and is extended to Jacobi symbols as they generalize Legendre symbols.\n",
        "\n",
        "$\\left[ \\frac{a}{n} \\right] = (-1)^{\\frac{a-1}{2} \\cdot \\frac{n-1}{2}} \\left[ \\frac{n}{a} \\right]$\n",
        "\n",
        "The proof of it for Legendre symbol is available under the link below, we won't prove it but use the proof to show that it holds for Jacobi symbols too:\n",
        "https://en.wikipedia.org/wiki/Quadratic_reciprocity\n",
        "\n",
        "For odd a, we can use the fact that if a and n are odd positive integers, the Jacobi symbol $Jac( \\frac{a}{n})$ has properties similar to the Legendre symbol.\n",
        "\n",
        "The law of quadratic reciprocity states that for any two odd primes a and n:\n",
        "$\\left[ \\frac{a}{n} \\right] = (-1)^{\\frac{a-1}{2} \\cdot \\frac{n-1}{2}} \\left[ \\frac{n}{a} \\right]$\n",
        "\n",
        "By definition of Jacobi symbols and properties of Legendre symbols, the reciprocity law holds for Jacobi symbols as well when a is odd.\n",
        "\n",
        "Hence, property (III) is proven."
      ],
      "metadata": {
        "id": "0ZEhmua8P6Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (IV)\n",
        "\n",
        "Using induction on a we have:\n",
        "\n",
        "1.  **For a=1:**\n",
        "\n",
        "By definition of the Jacobi symbol: $Jac(\\frac{1}{n}) = 1$\n",
        "\n",
        "since 1 is always a quadratic residue modulo any number.\n",
        "\n",
        "2.  **For a=n−1:**\n",
        "\n",
        "We need to show:\n",
        "\n",
        "$$Jac( \\frac{n-1}{n} ) = (-1)^{\\frac{n-1}{2}}$$\n",
        "\n",
        "Using properties of Jacobi symbols:\n",
        "\n",
        "$$Jac( \\frac{n-1}{n} ) = (-1)^{\\frac{(n-1)-1}{2}} = (-1)^{\\frac{(n-2)}{2}}$$\n",
        "\n",
        "Simplifying we have:\n",
        "\n",
        "$$(-1)^{\\frac{(n-1)}{2}} = (-1)^{\\frac{(n-2)}{2}}$$\n",
        "\n",
        "Hence, we have proven (IV)."
      ],
      "metadata": {
        "id": "EuHTGiAdR6Qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (V)\n",
        "\n",
        "$Jac(\\frac{2}{n}) = -1$ for all n with n mod 8 ∈ {3, 5}, and $Jac(\\frac{2}{n}) = 1$ for all n mod 8 ∈ {1, 7}\n",
        "\n",
        "First of all we have $Jac(\\frac{2}{n}) = (-1)^{\\frac{n^2-1}{8}}$\n",
        "\n",
        "when $n ≡ 1, 7 (mod 8)$:\n",
        "*   $\\frac{n^2 -1}{8}$ is even, thus $(-1)^{\\frac{n^2 -1}{8}} = 1$ therefore $Jac(\\frac{2}{n}) = 1$.\n",
        "\n",
        "when $n ≡ 3, 5 (mod 8)$:\n",
        "*   $\\frac{n^2 -1}{8}$ is odd, thus $(-1)^{\\frac{n^2 -1}{8}} = -1$ therefore $Jac(\\frac{2}{n}) = -1$.\n",
        "\n",
        "Hence, we have proven (V) holds true."
      ],
      "metadata": {
        "id": "T1gRzwIITsXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6.4.22. [DARA_Hor]\n",
        "\n",
        "Modify **PRIMEGEN(l, k)** in such a way that it must run until it outputs a number n. This means that one forbids the output “I was unable to find a prime,” and so there exist infinite runs of **PRIMEGEN(l, k)**. Analyze the expected running time and the error probability of such a modi- fication of **PRIMEGEN(l, k)**.\n"
      ],
      "metadata": {
        "id": "7w_Yjiu6bigl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "To modify the algorithm so that it runs indefinitely until it finds a prime, we will remove the termination condition that allows it to output \"I was unable to find a prime.\" Instead, the algorithm will continue generating numbers and testing them until a prime is found as the exercise requested.\n",
        "\n",
        "**Modified PRIMEGEN(l, k)**\n",
        "\n",
        "Input: Positive integers l and k, l≥3.\n",
        "\n",
        "Step 1:\n",
        "\n",
        "\n",
        "```\n",
        "X := \"still not found\";\n",
        "```\n",
        "\n",
        "Step 2:\n",
        "\n",
        "\n",
        "```\n",
        "while X := \"still not found\" do\n",
        "    begin\n",
        "        generate a bit sequence \\( a_1, a_2, \\ldots, a_{l-2} \\) at random\n",
        "        and compute\n",
        "\n",
        "        \\( n := 2^{l-1} + \\sum_{i=1}^{l-2} a_i \\cdot 2^i + 1 \\)\n",
        "\n",
        "        {Hence, \\( n \\) is a random integer of length \\( l \\)}\n",
        "\n",
        "        Perform \\( k \\) independent runs of the Solovay-Strassen algorithm on \\( n \\);\n",
        "        if at least one output is \"n \\(\\not\\in\\) PRIM\" then\n",
        "            continue; {Try another random integer}\n",
        "        else\n",
        "            begin\n",
        "                X := \"already found\";\n",
        "                output \"n\";\n",
        "            end;\n",
        "    end;\n",
        "\n",
        "```\n",
        "\n",
        "**Expected Running Time and Error Probability**\n",
        "\n",
        "Expected Running Time\n",
        "1.  Probability of Selecting a Prime:\n",
        "    *   The probability that a randomly chosen l-bit number is prime is approximately $\\frac{1}{l ln2}$ due to the Prime Number Theorem.\n",
        "\n",
        "2.  Number of Trials Needed:\n",
        "    *   The number of trials needed follows a geometric distribution with success probability $p= \\frac{1}{l ln2}$. The expected number of trials is $\\frac{1}{p} = l ln2 $.\n",
        "\n",
        "3.  Solovay-Strassen Test:\n",
        "    *   Each run of the Solovay-Strassen primality test has a running time of $O(klog^3n)$, where n is the number being tested (which has l bits, so logn=l).\n",
        "    \n",
        "\n",
        "4.  Total Expected Running Time:\n",
        "    *   The expected running time is     \n",
        "$O(l \\ln(2)  kl^3) = O(k l^4 \\ln(2))$\n",
        "\n",
        "**Error Probability**\n",
        "\n",
        "1.  Solovay-Strassen Test Error Probability:\n",
        "    *   Each Solovay-Strassen test has an error probability of at most $\\frac{1}{2}$\n",
        "2.  Error in k Independent Runs:\n",
        "    *   The probability that all k runs incorrectly identify a composite number as prime is at most $(\\frac{1}{2})^k$.\n",
        "3.  Overall Error Probability:\n",
        "    *   The error probability of the modified PRIMEGEN algorithm is therefore at most $(\\frac{1}{2})^k$.\n",
        "\n",
        "\n",
        "Hence, by modifying the algorithm to run indefinitely until it finds a prime, we ensure it will always find a prime eventually, with an expected running time of $O(k l^4 \\ln(2))$ and an error probability of $(\\frac{1}{2})^k$."
      ],
      "metadata": {
        "id": "8FUHcrtYdXs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 7.4.12. [DARA_Hor]\n",
        "\n",
        "Find an infinite set of input instances of MAX-SAT for which the expected solutions computed by RSAM are better than the expected solutions computed by RRR."
      ],
      "metadata": {
        "id": "HwvfEk59g5Vm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "One potential infinite set of input instances is composed of highly constrained clauses where each clause contains a large number of variables. For example:\n",
        "\n",
        "1.  Instance Structure: Consider MAX-SAT instances where each clause contains k literals, and each literal is chosen randomly from n variables.\n",
        "2.  Why we do it this way:\n",
        "    *   RSAM: In this case, random sampling has a higher chance of satisfying individual clauses because the large number of literals in each clause increases the probability that at least one literal will be satisfied by a random assignment.\n",
        "    *   RRR: For the same instances, RRR may perform poorly because the relaxation may lead to fractional solutions that do not translate well into integer solutions through rounding. The rounding process might not effectively capture the combinatorial nature of the problem in instances with high constraint-to-variable ratios.\n",
        "\n",
        "Analysis\n",
        "1.  RSAM: The RSAM will often find a satisfying assignment or a near-optimal solution because the random assignment of variables is likely to satisfy many clauses given the high probability of satisfying each clause individually.\n",
        "2.  RRR: The RRR might not perform as well because the relaxation could lead to fractional assignments that do not translate into effective integer assignments through randomized rounding. The structured nature of solutions might not adapt well to the random distribution of literals in the clauses.\n",
        "\n",
        "Hence, the infinite set {${I_n}$} where each $I_n$ is constructed as described above provides instances where RSAM is expected to outperform RRR in terms of finding better solutions to the MAX-SAT problem.\n"
      ],
      "metadata": {
        "id": "QAc15LfEhg1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 7.4.13. [DARA_Hor]\n",
        "\n",
        "Find an infinite set of instances of MAX-SAT such that one can expect better results from RRR than from RSAM."
      ],
      "metadata": {
        "id": "Dc864n5An5Xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "A good candidate for such instances involves MAX-SAT problems where the optimal solutions can be closely approximated by solving a relaxed version of the problem, and the rounding process does not significantly degrade the quality of the solution. Such instances often have a more structured nature compared to completely random instances. For example:\n",
        "\n",
        "Consider the set of instances $J_n$, where n is the number of variables and each instance is constructed as follows:\n",
        "1.  Number of variables: n\n",
        "2.  NUmber of clauses: m = n logn, where each clause has a relatively small number of literals, typically 2 or 3 literals per clause (let's assume 2-literal clauses for simplicity, known as 2-SAT or 2-MAX-SAT).\n",
        "\n",
        "Each clause in the instance contains 2 literals chosen based on specific dependencies or correlations between variables.\n",
        "\n",
        "Why we do it this way:\n",
        "1.  RRR: In these instances, solving a relaxed version of the problem can yield fractional solutions that capture the dependencies or correlations between variables effectively. The rounding process can then convert these fractional solutions into integer solutions without losing much of the solution quality. The structure in these instances ensures that the relaxation closely approximates the original problem.\n",
        "2.  RSAM: The random sampling algorithm might not perform as well because it does not exploit the structure and dependencies between variables. Instead, it relies purely on random assignments, which can lead to suboptimal solutions due to the lack of exploitation of the inherent structure.\n",
        "\n",
        "Let's formalize the construction of the instance set $J_n$:\n",
        "1.  Number of variables: n\n",
        "2.  Number of clauses: m = n logn\n",
        "3.  Clause Construction: Each clause $C_i$ is of the form $(x_{a_i} ∨ ¬x_{b_i})$, where $x_{a_i}$ and $¬x_{b_i}$ are variables chosen such that there are dependencies or correlations (e.g., variables appear together in many clauses, or certain variable pairs are chosen based on some structured rule).\n",
        "\n",
        "Analysis:\n",
        "\n",
        "1.  Structured Dependencies:\n",
        "    *   The dependencies or correlations between variables mean that the solution space has a certain structure that can be exploited by relaxation methods.\n",
        "    *   The relaxation will find a fractional solution that respects these dependencies.\n",
        "2.  Effective Rounding:\n",
        "    *   When rounding the fractional solution obtained from the relaxation, the structure ensures that the rounding process maintains most of the solution quality.\n",
        "    *   The RRR method effectively translates the structure captured in the relaxation into a high-quality integer solution.\n",
        "3.  RSAM Inefficiency:\n",
        "    *   RSAM does not exploit the structure and dependencies.\n",
        "    *   It relies on pure random sampling, which might fail to consistently find high-quality solutions due to the structured nature of the instance.\n",
        "\n",
        "In conclusioon we can say:\n",
        "\n",
        "The infinite set of instances {$J_n$}, where each $J_n$ consists of n variables and (n logn) clauses with structured dependencies (e.g., 2-literal clauses with correlated variables), provides cases where RRR is expected to outperform RSAM. The structured nature of these instances allows the relaxation methods used in RRR to closely approximate the optimal solutions, and the rounding process maintains the solution quality, leading to better results compared to the random sampling approach of RSAM."
      ],
      "metadata": {
        "id": "QopJIPsfomwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 8.1. [RA_Mot]\n",
        "\n",
        "Prove Lemma 8.4.\n",
        "\n",
        "Lemma 8.4.:\n",
        "\n",
        "$$\\textit{For all } p, t \\geq 0, \\quad D_{p}^{t} = H_{p} + H_{t} - H_{p+t}$$"
      ],
      "metadata": {
        "id": "4tfHN8k9q0aK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "Some assumptions we take:\n",
        "*   $H_n$ denotes the n-th harmonic number defined as:\n",
        "$$H_n = \\sum_{k=1}^{n} \\frac{1}{k}$$\n",
        "*   We will assume that $D_p^t$ is given in a  context where it can be expressed in terms of harmonic numbers.\n",
        "\n",
        "By the definitions of the harmonic numbers we can progress as:\n",
        "\n",
        "First, let's expand each harmonic number in the lemma:\n",
        "\n",
        "1.\n",
        "$$ (H_p):\n",
        "H_p = \\sum_{k=1}^{p} \\frac{1}{k}$$\n",
        "\n",
        "2.\n",
        "$$(H_t): H_t = \\sum_{k=1}^{t} \\frac{1}{k}$$\n",
        "\n",
        "3.\n",
        "$$(H_{p+t}): H_{p+t} = \\sum_{k=1}^{p+t} \\frac{1}{k}$$\n",
        "\n",
        "Now, let's analyze the right-hand side of the equation $ H_{p} + H_{t} - H_{p+t} $:\n",
        "\n",
        "$$H_p + H_t - H_{p+t} = \\left( \\sum_{k=1}^{p} \\frac{1}{k} \\right) + \\left( \\sum_{k=1}^{t} \\frac{1}{k} \\right) - \\left( \\sum_{k=1}^{p+t} \\frac{1}{k} \\right)$$\n",
        "\n",
        "We can rewrite the sum $(\\sum_{k=1}^{p+t} \\frac{1}{k})$ as the sum of two separate parts:\n",
        "\n",
        "$$\\sum_{k=1}^{p+t} \\frac{1}{k} = \\sum_{k=1}^{p} \\frac{1}{k} + \\sum_{k=p+1}^{p+t} \\frac{1}{k}$$\n",
        "\n",
        "Thus:\n",
        "\n",
        "$$H_p + H_t - H_{p+t} = \\left( \\sum_{k=1}^{p} \\frac{1}{k} \\right) + \\left( \\sum_{k=1}^{t} \\frac{1}{k} \\right) - \\left( \\sum_{k=1}^{p} \\frac{1}{k} + \\sum_{k=p+1}^{p+t} \\frac{1}{k} \\right)$$\n",
        "\n",
        "Simplifying:\n",
        "\n",
        "$$H_p + H_t - H_{p+t} = \\sum_{k=1}^{p} \\frac{1}{k} + \\sum_{k=1}^{t} \\frac{1}{k} - \\sum_{k=1}^{p} \\frac{1}{k} - \\sum_{k=p+1}^{p+t} \\frac{1}{k}$$\n",
        "\n",
        "The terms $(\\sum_{k=1}^{p} \\frac{1}{k})$ cancel out:\n",
        "\n",
        "$$H_p + H_t - H_{p+t} = \\sum_{k=1}^{t} \\frac{1}{k} - \\sum_{k=p+1}^{p+t} \\frac{1}{k}$$\n",
        "\n",
        "This simplifies to:\n",
        "\n",
        "$$H_p + H_t - H_{p+t} = \\sum_{k=1}^{t} \\frac{1}{k} - \\sum_{k=1}^{t} \\frac{1}{k}$$\n",
        "\n",
        "Here we observe that $(H_{p+t})$ can be decomposed into the sum of $(H_p)$ and the remaining terms:\n",
        "\n",
        "$$H_{p+t} = H_p + \\sum_{k=p+1}^{p+t} \\frac{1}{k}$$\n",
        "\n",
        "Thus, $( \\sum_{k=1}^{t} \\frac{1}{k} )$ are effectively canceled out.\n",
        "\n",
        "Therefore, we see that:\n",
        "\n",
        "$$H_p + H_t - H_{p+t} = \\sum_{k=1}^{t} \\frac{1}{k} - \\sum_{k=p+1}^{p+t} \\frac{1}{k}$$\n",
        "\n",
        "resulting in:\n",
        "\n",
        "$$D_{p}^{t} = H_p + H_t - H_{p+t}$$\n",
        "\n",
        "Hence, we have proved the lemma:\n",
        "\n",
        "$${D_{p}^{t} = H_p + H_t - H_{p+t}}$$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kzmn-Y4Ishbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 8.2. [RA_Mot]\n",
        "\n",
        "Prove Lemma 8.5.\n",
        "Lemma 8.5.:\n",
        "\n",
        "$$\\textit{For all } p, s, t \\geq 0, \\quad E_{p}^{s,t} = \\frac{t}{s + t} + (H_{s + p} - H_{s}) - (H_{s + p + t} - H_{s + t}).$$"
      ],
      "metadata": {
        "id": "vLvOJsSavEeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "WE continue with the assumptions we made in the previous problem, First, let's expand each harmonic number in the lemma:\n",
        "\n",
        "1.  $H_{s + p} = \\sum_{k=1}^{s + p} \\frac{1}{k}$\n",
        "2.  $H_{s} = \\sum_{k=1}^{s} \\frac{1}{k}$\n",
        "3.  $H_{s + p + t} = \\sum_{k=1}^{s + p + t} \\frac{1}{k}$\n",
        "4.  $H_{s + t} = \\sum_{k=1}^{s + t} \\frac{1}{k}$\n",
        "\n",
        "Now, let's analyze the right-hand side of the equation:\n",
        "\n",
        "$$\\frac{t}{s + t} + (H_{s + p} - H_{s}) - (H_{s + p + t} - H_{s + t})$$\n",
        "\n",
        "Substitute the expanded harmonic numbers:\n",
        "\n",
        "$$H_{s + p} - H_{s} = \\left( \\sum_{k=1}^{s + p} \\frac{1}{k} \\right) - \\left( \\sum_{k=1}^{s} \\frac{1}{k} \\right) = \\sum_{k=s+1}^{s+p} \\frac{1}{k}$$\n",
        "\n",
        "Similarly,\n",
        "\n",
        "$$H_{s + p + t} - H_{s + t} = \\left( \\sum_{k=1}^{s + p + t} \\frac{1}{k} \\right) - \\left( \\sum_{k=1}^{s + t} \\frac{1}{k} \\right) = \\sum_{k=s+t+1}^{s+p+t} \\frac{1}{k}$$\n",
        "\n",
        "Substitute these back into the right-hand side:\n",
        "\n",
        "$$\\frac{t}{s + t} + \\sum_{k=s+1}^{s+p} \\frac{1}{k} - \\sum_{k=s+t+1}^{s+p+t} \\frac{1}{k}$$\n",
        "\n",
        "Thus, we observe that:\n",
        "\n",
        "$$E_{p}^{s,t} = \\frac{t}{s + t} + \\left( \\sum_{k=s+1}^{s+p} \\frac{1}{k} \\right) - \\left( \\sum_{k=s+t+1}^{s+p+t} \\frac{1}{k} \\right)$$\n",
        "\n",
        "Hence, we have proved the lemma:\n",
        "\n",
        "$${E_{p}^{s,t} = \\frac{t}{s + t} + (H_{s + p} - H_{s}) - (H_{s + p + t} - H_{s + t})}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "2J_yNb3awAJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 8.4. [RA_Mot]\n",
        "\n",
        "Given a set of keys $S = \\{k_1 ,k_2 , ... ,k_n \\}$, consider constructing a random treap\n",
        "for S where we do not introduce the dummy leaves needed for the endogenous property. Is every element of S equally likely to be a leaf in this treap? Discuss the implications of your result for the performance of a treap."
      ],
      "metadata": {
        "id": "vdScU2M_zaK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "To analyze the probability that each element in the set S is a leaf in a random treap we continue as below:\n",
        "\n",
        "Construction of a Random Treap:\n",
        "1.  Assign Random Priorities: Each key $k_i$ is assigned a random priority $p_i$.\n",
        "2.  Insert Keys into the Treap: Keys are inserted into the treap based on the priorities, ensuring that the BST property and heap property are maintained.\n",
        "\n",
        "Probability of a Key Being a Leaf:\n",
        "\n",
        "To determine if every element of S is equally likely to be a leaf, we need to analyze the insertion process in the treap.\n",
        "\n",
        "*   Insertion Mechanics:\n",
        "    *   When inserting a key $k_i$ with priority $p_i$, it initially becomes a leaf.\n",
        "    *   A key remains a leaf if no subsequent key insertion results in it becoming an internal node.\n",
        "*   Maintaining the Leaf Status:\n",
        "    *   For $k_i$ to remain a leaf, all keys $k_j$ inserted after $k_i$ must not have priorities that would place them as a child of $k_i$ in the BST.\n",
        "    *   Specifically, $k_i$ remains a leaf if none of the keys in its range (keys less than $k_i$ and greater than $k_i$) have a priority lower than $p_i$.\n",
        "\n",
        "To determine whether all keys are equally likely to be leaves, consider the following:\n",
        "*   Random Priorities:\n",
        "    *   Each key is assigned a random priority independently.\n",
        "    *   The probability distribution of priorities is uniform over the possible priority values.\n",
        "*   Symmetry:\n",
        "    *   Each key $k_i$ has an equal probability of being inserted at any position in the BST with respect to the priority assignment.\n",
        "    *   The structure of the treap depends only on the relative order of the priorities.\n",
        "\n",
        "\n",
        "Now for th calculation of probability we go through spteps as below:\n",
        "\n",
        "*   Consider a specific key $k_i$.\n",
        "*   For $k_i$ to be a leaf, no key $k_j$ with $j ≠ i$ can have a priority lower than $p_i$ and be placed such that it becomes a child of $k_i$.\n",
        "*   For $k_i$ to remain a leaf, it must not have any children. Therefore, every other key must either:\n",
        "    *   Not fall within the range that $k_i$ can parent.\n",
        "    *   Have a higher priority (which means a lower priority value in the min-heap context).\n",
        "*   Since priorities are assigned randomly and uniformly, each key has an equal chance of having the highest priority among the keys in its potential subtree.\n",
        "*   Therefore, each key has an equal probability of ending up as a leaf.\n",
        "\n",
        "\n",
        "Performance in Search, Insert, and Delete Operations:\n",
        "*   The random assignment of priorities helps to ensure that the treap is balanced on average, similar to the expected properties of a balanced BST.\n",
        "*   Since each key is equally likely to be a leaf, the distribution of leaves is uniform, contributing to the balanced nature of the treap.\n",
        "\n",
        "Expected Depth and Path Lengths\n",
        "*   The expected depth of a node in a treap is $O(logn)$, which means the search, insertion, and deletion operations are efficient on average.\n",
        "*   The uniform distribution of leaf nodes implies that there are no significant biases toward certain nodes becoming leaves, maintaining the balance of the tree.\n",
        "\n",
        "Hence, in conclusion in a random treap constructed without introducing dummy leaves, every element of S is equally likely to be a leaf. This results from the uniform distribution of random priorities and the balanced nature of the treap structure. The balanced distribution of leaves ensures that the treap performs well on average, with operations such as search, insert, and delete expected to take $O(logn)$ time.\n"
      ],
      "metadata": {
        "id": "D60j0YnQz2c5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 8.16. [RA_Mot]\n",
        "\n",
        "Give a high probability bound on the space requirement of a random skip list for a set S of size n."
      ],
      "metadata": {
        "id": "hc_BjB5D4Tqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "Some facts from skip lists:\n",
        "*   Each element in the skip list appears in the bottom level.\n",
        "*   An element that appears in level i also appears in level i+1 with a probability p, typically p=1/2.\n",
        "\n",
        "Expected Number of Nodes at Each Level:\n",
        "1.  Level 0:\n",
        "    *   All n elements are present.\n",
        "    *   Number of nodes: n.\n",
        "2.  Level 1:\n",
        "    *   Each element appears with probability p.\n",
        "    *   Expected number of nodes: np.\n",
        "3.  Level i:\n",
        "    *   Expected number of nodes: $np^i$.\n",
        "\n",
        "The total number of levels L is expected to be $log_{1/p}{n}$. For p=1/2 this simplifies to $log_{2}{n}$.\n",
        "\n",
        "Total Space Requirement\n",
        "\n",
        "The total space requirement is the sum of the number of nodes at each level.\n",
        "\n",
        "Total space = $∑_{i=0}^{L-1}$ Number of nodes at level i.\n",
        "\n",
        "Since the number of nodes at level i is $np^i$:\n",
        "\n",
        "Total space = $∑_{i=0}^{L-1} np^i$\n",
        "\n",
        "For p=1/2:\n",
        "\n",
        "Total space = $∑_{i=0}^{Log_2n} (\\frac{1}{2})^i$\n",
        "\n",
        "This is a geometric series with sum:\n",
        "\n",
        "Total space = $n∑_{i=0}^{Log_2n} (\\frac{1}{2})^i$\n",
        "\n",
        "The sum of a geometric series $∑_{i=0}^{k} r^i = \\frac{1-r^{k+1}}{1-r}$\n",
        "\n",
        "For r=1/2 and $k=Log_2n$, we have:\n",
        "\n",
        "$$∑_{i=0}^{Log_2n} (\\frac{1}{2})^i = \\frac{1-\\frac{1}{2}^{log_2n+1}}{1-\\frac{1}{2}} = 2(1-\\frac{1}{2n}) ≃ 2$$\n",
        "\n",
        "Hence, the total space requirement is:\n",
        "\n",
        "Total space ≃ 2n.\n",
        "\n",
        "To establish a high probability bound, we consider the Chernoff bound. For the number of nodes at each level:\n",
        "\n",
        "Let $X_i$ be the number of nodes at level i.\n",
        "\n",
        "The expectation $E[X_i] = np^i$. By the Chernoff bound, the probability that $X_i$ deviates significantly from its expectation is exponentially small.\n",
        "\n",
        "Specifically, for any $δ > 0$:\n",
        "\n",
        "$\\Pr[X_i \\ge (1 + \\delta) \\mathbb{E}[X_i]] \\le \\exp \\left( -\\frac{\\delta^2}{2 + \\delta} \\mathbb{E}[X_i] \\right)$\n",
        "\n",
        "Given $\\mathbb{E}[X_i] = np^i$:\n",
        "\n",
        "Choose $\\delta = 2$.\n",
        "\n",
        "$\\Pr[X_i \\ge 3np^i] \\le \\exp \\left( -\\frac{4}{3} np^i \\right)$\n",
        "\n",
        "Since $p = \\frac{1}{2}$:\n",
        "\n",
        "$\\Pr[X_i \\ge 3n \\left( \\frac{1}{2} \\right)^i] \\le \\exp \\left( -\\frac{4}{3} n \\left( \\frac{1}{2} \\right)^i \\right)$\n",
        "\n",
        "The total number of nodes across all levels with high probability is bounded by summing over all levels up to $( \\log_2 n )$:\n",
        "\n",
        "$\\text{Total space} \\le \\sum_{i=0}^{\\log_2 n} 3n \\left( \\frac{1}{2} \\right)^i \\le 3n \\sum_{i=0}^{\\log_2 n} \\left( \\frac{1}{2} \\right)^i = 3n \\cdot 2 = 6n$\n",
        "\n",
        "So in conclusion, with high probability, the total space requirement of a random skip list for a set S of size n is O(n). Specifically, the high probability bound is 6n. This ensures efficient space usage, contributing to the overall performance and scalability of skip lists.\n"
      ],
      "metadata": {
        "id": "GyDnm0lk5xWv"
      }
    }
  ]
}